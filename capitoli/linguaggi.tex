\setchapterpreamble[u]{\margintoc}
\chapter{Linguaggi e Grammatiche}\label{cha:linguaggi+grammatiche}
\labch{Linguaggi e Grammatiche}

\section{Linguaggi}
iIniziamo con le definizioni di base che saranno fondamentali in tutto il testo.

Un \textbf{simbolo} o \textbf{carattere} è un qualsiasi oggetto.


\begin{definition}[Alfabeto]\label{def:alfabeto}
Un \keyword{alfabeto}, normalmente indicato con $\Sigma$, è un insieme finito e non vuoto di simboli.
\end{definition}

Esempi di alfabeti sono \texttt{abcdefghijklmnopqrstuvwxyz}, e l'insieme di cifre \texttt{0123456789}.
Siccome un alfabeto è un insieme, l'ordine dei simboli non è rilevante.
In altre parole \texttt{9876543210} è sempre l'alfabeto delle cifre.
Nel seguito useremo $\Sigma_{L}$ per indicare l'alfabeto delle lettere minuscole, $\Sigma_{C}$ per l'alfabeto delle cifre,
$\Sigma_{B}$ per l'alfabeto delle cifre binarie.


La giustapposizione (o concatenazione) di simboli permette di creare parole o stringhe, quali ad
esempio \texttt{parola} o \texttt{2301}.
La concatenazione di due simboli viene rappresentata semplicemente scrivendo un simbolo dopo l'altro.


\begin{definition}[Parola]\label{def:parola}
Sia $\Sigma$ un alfabeto.
Allora una \keyword{parola} è una sequenza $\sigma_{1}\cdots\sigma_{n}$ di simboli, non necessariamente
distinti, dell'alfabeto $\Sigma$.
Una parola viene normalmente rappresentata tramite la giustapposizione dei
simboli che compongono la sequenza, rispettando l'ordine.
\end{definition}

Normalmente usiamo le ultime lettere dell'alfabeto latino (ad esempio $w$, $x$,
$y$, $z$) per rappresentare parole.
La \keyword{lunghezza} di una parola è il numero di simboli nella sequenza.
La lunghezza della parola $z$ viene indicata con $|z|$.

Alcuni simboli sono speciali perchè hanno un significato particolare e non fanno parte di nessun alfabeto $\Sigma$.
Il primo simbolo speciale che vediamo è $\epsilon$ e rappresenta la stringa vuota,
formata dalla sequenza di zero simboli.

\begin{definition}[Linguaggio]\label{def:linguaggio}
Dato un alfabeto $\Sigma$, un \keyword{linguaggio} $L$ è un insieme di parole su $\Sigma$.
\end{definition}

Sebbene l'alfabeto sia finito, un linguaggio potrebbe contenere un numero
infinito di parole.
Diventa quindi importante capire quando un linguaggio infinito ha una
rappresentazione finita.
Notare che praticamente tutti i linguaggi rilevanti sono infiniti, ma con
rappresentazione finita.
Prendiamo ad esempio JSON: abbiamo una specifica formale (quindi una sequenza di
caratteri corrisponde ad un documento JSON se e solo se soddisfa la specifica),
e l'insieme dei documenti JSON è infinito.

\begin{example}\label{exa:numeri}
Un numero è formato da una parte intera che consiste unicamente di cifre e,
opzionalmente, da una parte frazionaria che consiste unicamente di cifre.
Se la parte frazionaria esiste, allora la parte intera e la parte frazionaria
sono separate da un punto.
La parte intera non può iniziare con \texttt{0} e la parte frazionaria non può
finire con \texttt{0}.
L'insieme di tutti i numeri è un linguaggio (infinito).
\end{example}

La descrizione nell'\cref{exa:numeri} è di natura insiemistica:  il
linguaggio è visto come l'insieme delle parole che lo compongono.
Quando vogliamo studiare un linguaggio, esistono tre punti di vista alternativi: (1) considerare come sia possibile generare
tutte le parole di un linguaggio, (2) descrivere una procedura che determini se
una parola appartiene al linguaggio, (3) fornire una proprietà che è soddisfatta da tutte e sole le parole del linguaggio.
Si noti che la definizione di linguaggio non cambia.
Nel seguito vedremo come questi tre punti di vista si complementino e
interagiscono fra loro.

L'approccio, basato sulla procedura per determinare se una parola
appartiene al linguaggio, ci porta a definire il primo fondamentale problema
computazionale, detto problema dell'\keyword{appartenenza} ad un linguaggio.


\begin{problem}[Appartenenza]\label{pb:appartenenza}
Siano $L$ un linguaggio e $z$ una parola, entrambi sull'alfabeto $\Sigma$.
Determinare se $z$ \keyword{appartiene} a $L$ o, in altre parole, se $z$ sia una parola del linguaggio $L$.
\end{problem}

Il problema dell'appartenenza è un \keyword{problema di decisione}, perchè
ammette solo due risposte: sì o no.
La nozione di  concatenazione non si applica solo ai caratteri, ma anche a stringhe e linguaggi.


\begin{definition}[Concatenazione]\label{def:concatenazione-parole}
Siano $w$ e $x$ due parole.
La loro \keyword{concatenazione} $wx$ è ottenuta prendendo $w$ e facendo seguire a questa la stringa  $x$.
Più formalmente, se $w=a_{1}\cdots a_{|w|}$ e $x=b_{1}\cdots b_{|w|}$, allora la loro concatenazione $wx$ è la stringa
$a_{1}\cdots a_{|w|} b_{1}\cdots b_{|w|}$.
\end{definition}

\begin{definition}[Concatenazione di linguaggi]\label{def:concatenazione-linguaggi}
Siano $L_{1}$ e $L_{2}$ due linguaggi, rispettivamente su alfabeto $\Sigma_{1}$ e $\Sigma_{2}$.
Allora la loro concatenazione $L_{1}L_{2}$ è uguale alla concatenazione di tutte le coppie ordinate di parole di $L_{1}$
e $L_2$.
Formalmente, $L_{1}L_{2} = \{ w_{1}w_2 : w_{1}\in L_{1}, w_{2}\in L_2\}$.
\end{definition}

Una definizione equivalente di concatenazione di linguaggi è $L_{1}L_{2} = \{ w_{1}w_2 : (w_{1}, w_{2})\in L_{1} \times L_2\}$.
Si noti anche che l'alfabeto del linguaggio $L_1 L_2$ è $\Sigma_{1} \cup \Sigma_{2}$.


\begin{definition}\label{def:potenza-linguaggio}
Sia $L$ un linguaggio e sia $k$ un numero intero strettamente positivo.
Allora la $k$-esima \keyword{potenza} di $L$, denotata con $L^k$, è l'insieme di tutte le stringhe ottenute concatenando
$k$ parole, non necessariamente distinte, del linguaggio $L$.
\end{definition}

Per convenzione, si indica con $L^{0} = \{ epsilon \}$.
Quindi possiamo vedere $L^{1} =L$, mentre $L^{k} = L^{k-1} \Sigma$ se $k>1$.
Una variante della \cref{def:concatenazione-linguaggi} consiste nella definizione di potenza di un alfabeto.

\begin{definition}\label{def:potenza-alfabeto}
Sia $\Sigma$ un alfabeto e sia $k$ un numero intero strettamente positivo.
Allora la $k$-esima \keyword{potenza} di $\Sigma$, denotata con $\Sigma^k$, è l'insieme di tutte le stringhe di
lunghezza $k$ sull'alfabeto $\Sigma$.
\end{definition}

Per convenzione, si indica con $\Sigma^{0} = \{ \epsilon \}$, esattamente come nel caso di potenza di un linguaggio.
Vediamo $\Sigma^{1}$ come il linguaggio formato da tutte le parole di lunghezza $1$ prese dall'alfabeto
$\Sigma$, mentre $\Sigma^{k} = \Sigma^{k-1} \Sigma$ se $k>1$.
Non possiamo dire $\Sigma^{1} = \Sigma$ perchè il primo è un insieme di parole e il secondo è un
insieme di simboli.

\begin{example}\label{exa:L3}
L'alfabeto $\Sigma_{B}^{3}$ è formato dalle stringhe \texttt{000}, \texttt{001}, \texttt{010}, \texttt{011}, \texttt{100}, \texttt{101}, \texttt{110}, \texttt{111}.
\end{example}


La nozione di chiusura permette di generalizzare la potenza al caso $k=\infty$.




\begin{definition}\label{def:punto-fisso}
Sia $A$ un insieme non vuoto e sia $\phi$ una funzione con mappa insiemi in insiemi.
Allora $A$ è un \keyword{punto fisso} per $\phi$ se $\phi(A) \subseteq A$.
\end{definition}

In altre parole, $A$ è un punto fisso se l'applicazione di $\phi$ non ``cambia'' $A$.
Ovviamente una funzione $\phi: X\mapsto Y$ potrebbe non avere punti fissi e potrebbe anche avere più di un punto fisso.
Noi siamo interessati ai \emph{minimi punti fissi} che contengono un insieme $A$: i più piccoli insiemi $B\supseteq A$
tali che $B$ sia un punto fisso per $\phi$.

\begin{definition}\label{def:kleene}
Sia $\Sigma$ un alfabeto.
Allora la sua \keyword{chiusura di Kleene}, denotata con $\Sigma^{*}$, è l'unione infinita di potenze
$\bigcup_{k=0}^{\infty} \Sigma^k = \Sigma^0 \cup \Sigma^1 \cup \cdots$.
\end{definition}

\begin{proposition}\label{prop:kleene-punto-fisso}
Sia $\Sigma$ un alfabeto.
Allora $\Sigma^{*}$ è il minimo punto fisso di $\Sigma \cup \{\epsilon\}$ rispetto alla funzione
chiusura di Kleene come minimo punto fisso di $L\cup \{\epsilon\}$ rispetto alla funzione $\phi$ che mappa ogni
linguaggio $L$ in $\phi(L) = L^{2}$.
\end{proposition}

\begin{example}\label{exa:chiusura-kleene}
$\Sigma_{B}^{*} = \{\mathtt{\epsilon},\mathtt{0},\mathtt{1},\mathtt{00},\mathtt{01},\mathtt{10},\mathtt{100},\mathtt{000},\ldots \}$.
\end{example}

Adesso possiamo introdurre la notazione più utilizzata per specificare un linguaggio costruito su un determinato alfabeto.


\begin{observation}\label{obs:linguaggio}
Un linguaggio $L$ su alfabeto $\Sigma$ è un sottoinsieme di stringhe in $ \Sigma^*$,
quindi $L\subseteq \Sigma^*$.
\end{observation}

Siccome ogni linguaggio è un insieme, il simbolo $\emptyset$ denota anche il \keyword{linguaggio vuoto} (notare che
$\emptyset\in\Sigma^k,\,|\emptyset|=0$), che è
diverso dal linguaggio $\{\epsilon\}$ che consiste esattamente della stringa vuota.
Infatti $|\{\varepsilon\}|=1$.
Infine si noti che $\Sigma^*$ è sempre un insieme infinito.
Vediamo adesso alcuni esempi di linguaggi sull'alfabeto $\Sigma_{B}$.


\begin{example}\label{exa:0n01}
Le stringhe che consistono in $n$ \texttt{0} seguiti da $n$ \texttt{1}:
$\{\varepsilon,\mathtt{01},\mathtt{0011},\mathtt{000111},\ldots\}$.
\end{example}

\begin{example}\label{exa:0=1}
le stringhe con un uguale numero di 0 e di 1:
$\{\varepsilon,\mathtt{01},\mathtt{10},\mathtt{0011},\mathtt{0110},\mathtt{0101},\mathtt{1001},\ldots\}$.
\end{example}

\begin{example}\label{exa:numeri-primi-binari}
le stringhe che codificano un numero primo:
$\{\mathtt{10},\mathtt{11},\mathtt{101}, \mathtt{111}, \ldots\}$.
\end{example}

\begin{example}\label{exa:numeri-primi-unari}
le stringhe che sono una codifica unaria di un numero primo, senza usare \texttt{0}:
$\{\mathtt{11},\mathtt{111},\mathtt{11111}, \mathtt{1111111}, \ldots\}$.
\end{example}

L'\cref{exa:numeri-primi-unari} è interessante perchè l'alfabeto effettivamente usato ha un solo simbolo.
In altre parole, non sono necessari due simboli per le nozioni di alfabeto e linguaggio.


\begin{observation}\label{obs:linguaggi-banali}
Sia $\Sigma$ un alfabeto.
Allora $\emptyset$, $\{\varepsilon\}$, e $\Sigma^{k}$ per ogni intero $k\ge 1$ sono tutti linguaggi per l'alfabeto $\Sigma$.
\end{observation}

Notiamo che tutti gli esempi di linguaggi che abbiamo dato in questa sezione sono basati sulla descrizione di una
proprietà che è vera per tutte e sole le parole del linguaggio.
Questo vuole dire che stiamo considerando una visione \emph{insiemistica} dei linguaggi.
Vedremo presto che questa non è l'unica visione possibile.


\section{Grammatiche}\label{sec:grammatiche}

Mentre la \ref{def:linguaggio} vede un linguaggio come un insieme, in questa sezione andiamo ad introdurre il concetto
di grammatica: ciò ci porterà a vedere come sia possibile \emph{generare} tutte e sole le parole appartenenti ad un linguaggio.


\begin{definition}[Grammatica]\label{def:grammatica}
Una \keyword{grammatica} $G$ è una quadrupla $G=\langle V, T, P, \mathsf{S} \rangle$ dove:
\begin{itemize}
	\item $V$ è un insieme finito di \keyword{variabili} o non terminali;
	\item $T$ è un insieme finito di simboli \keyword{terminali}, ovvero i simboli dell'alfabeto di riferimento,
	  disgiunto dalle variabili.
Quindi $V \cap T=\emptyset$;
	\item $P$ è un insieme finito di \textbf{produzioni} o regole;
	\item $\mathsf{S}\in V$ è il \keyword{simbolo iniziale} ($\mathsf{S}$ rappresenta ``start'').
\end{itemize}
\end{definition}


Dobbiamo ancora fornire la definizione di produzione.

\begin{definition}\label{def:produzione}
Una \keyword{produzione} $\alpha \to \beta$ formata da tre parti:
\begin{itemize}
\item una stringa non vuota $\alpha$, detta \keyword{testa},  sull'alfabeto $V \cup T$,
	  \item il simbolo $\to$ della produzione;
\item una stringa $\beta$, detta \keyword{corpo},  sull'alfabeto $V \cup T$.
\end{itemize}
\end{definition}

Notiamo che sia la testa che il corpo di una produzione possono contenere sia terminali che variabili, senza alcuna
restrizione: possono quindi esserci solo terminali, solo variabili, oppure entrambi.
Anche l'ordine con cui appaiono non ha vincoli.
L'unica restrizione è che la testa non può essere la stringa vuota, mentre il corpo potrebbe essere la stringa vuota
($\beta = \epsilon$).
Convenzionalmente, per evitare ambiguità, il simbolo di produzione $\to$ non appartiene a $V\cup T$.


Ad ogni grammatica $G=\langle V, T, P, S \rangle$ possiamo associare il linguaggio generato da $G$.
Intuitivamente, si parte dal simbolo iniziale $S$ e si applica ripetutamente una produzione.
L'applicazione di una produzione $\alpha\to\beta$ consiste nell'individuare $\alpha$ nella sottostringa attuale e
sostituirla con $\beta$.
Dopo ogni applicazione si ottiene una nuova stringa attuale e il processo può ripetersi, anche applicando una produzione
diversa da quella utilizzata nel passo precedente.
Quando la stringa attuale è formata da soli simboli terminale, tale stringa è una delle parole del linguaggio.
Il processo di ripetute applicazioni di produzioni si chiama derivazione.

Per semplificare alcune parti, introduciamo la definizione di forma sentenziale.

\begin{definition}[Forma sentenziale]\label{def:forma-sentenziale}
Sia \gramm una grammatica.
Una \keyword{forma sentenziale} è una stringa sull'alfabeto $V\cup T$.
\end{definition}


\begin{example}\label{exa:0001}
Consideriamo il linguaggio $L$ su alfabeto $\Sigma_{B}$ delle parola che contengono esattamente un \texttt{1} e questo
carattere is deve trovare in ultima posizione.
Una grammatica $G=\langle V, T, P, S \rangle$ che genera il linguaggio $L$ ha $V=\{\mathsf{Z}, \mathsf{U}\}$,
$T=\{\mathtt{0}, \mathtt{1}\}$, e le produzioni $\mathsf{S}\to \mathsf{Z}\mathsf{U}$, $\mathsf{S}\to \mathsf{U}$,
$\mathsf{U}\to \mathtt{1}$, $\mathsf{Z}\to \mathsf{Z}\mathtt{0}$, and $\mathsf{Z}\to \mathtt{0}$.
\end{example}

Possiamo notare che la stringa \texttt{001} viene generata dalla grammatica $G$ tramite la seguente sequenza di
applicazioni di produzione:

\[\mathsf{S} \sprod{\mathsf{S}\to \mathsf{Z}\mathsf{U}} \mathsf{Z}\mathsf{U}  \sprod{\mathsf{Z}\to \mathsf{Z}\mathtt{0}} \mathsf{Z}\mathtt{0}\mathsf{U} \sprod{\mathsf{U}\to \mathtt{1}} \mathsf{Z}\mathtt{0}\mathtt{1} \sprod{\mathsf{Z}\to \mathtt{0}} \mathtt{0}\mathtt{0}\mathtt{1} \]

Questa derivazione non è l'unica possibile per generare la stringa \texttt{001} e la grammatica $G$ che abbiamo
descritto non è l'unica in grado di generare il linguaggio $G$.
Possiamo adesso dare la definizione formale di applicazione di una produzione.

\begin{definition}Applicazione di una produzione\label{def:applicazione-produzione}
Siano $\alpha$, $\beta$, $\gamma$, $\delta$ stringhe su alfabeto $V\cup T$.
Sia $\gramm$ una grammatica e sia \prodgen una sua produzione (quindi $\alpha\neq\epsilon$).
L'\keyword{applicazione} della produzione \prodgen alla stringa $\gamma\alpha\delta$ è denotata con
$\gamma\alpha\delta \sprod{\prodgen} \gamma\beta\delta$ e rappresenta il fatto che $\alpha$ viene sostituita con $\beta$.
Se la produzione \prodgen è facilmente identificabile, oppure se non ci interessa specificare la produzione usata, possiamo denotare l'applicazione indicando solo la grammatica $G$
con $\gamma\alpha\delta \sprod{G} \gamma\beta\delta$.
Se anche la grammatica coinvolta non è ambigua, possiamo ometterla usando la scrittura $\gamma\alpha\delta \sprod{} \gamma\beta\delta$.
\end{definition}

Per denotare in modo compatto l'effetto di una sequenza di applicazioni di produzioni, e definire il linguaggio generato
da una grammatica, introduciamo il concetto di
produzione estesa.

\begin{definition}[Applicazione estesa di una produzione]\label{def:applicazione-produzione-estesa}
Sia $\gramm$ una grammatica e siano $\alpha$, $\beta$ due forme sentenziali di $G$.
Allora possiamo scrivere $\alpha \eprod{G} \beta$ se esiste una sequenza
$\langle \gamma_{1}, \ldots, \gamma_{n}\rangle $ di $n$ forme sentenziali tali che $\alpha = \gamma_{1}$,
$\beta = \gamma_{n}$, e $\gamma_{i} \sprod{G} \gamma_{i+1}$ per ogni $1\le k< n$.
In questo caso diciamo che $\beta$ è il risultato dell'\keyword{applicazione estesa} di produzioni di $G$ alla stringa $\alpha$.
\end{definition}


\begin{definition}[linguaggio generato]\label{def:linguaggio-generato}
Sia \gramm una grammatica.
Il \keyword{linguaggio generato} da $G$, denotato con $L(G)$ è l'insieme $L(G)= \{ w\in T^{*}: S \eprod{G} w\}$.
\end{definition}

Inoltre la definizione di grammatica è estremamente poco vincolata, rendendo difficile capire quali sia il linguaggio
che una grammatica genera. Per questo motivo sono interessanti studiare grammatiche ristrette dove valgono proprietà più
stringenti di interesse sia per studiare le proprietà dei linguaggi generati che per risolvere più efficientemente il
problema di appartenenza.
Una prima classificazione delle grammatiche corrisponde alla gerarchia di Chomsky che classifica le grammatiche in tipo
0, 1, 2, 3.

\begin{definition}\label{def:tipo-0}
Ogni grammatica \gramm definita secondo la \cref{def:grammatica} è di tipo 0.
\end{definition}

\begin{definition}\label{def:tipo-1}
Ogni grammatica \gramm di tipo 0 per cui tutte le sue produzioni hanno lunghezza almeno pari a alla testa è di tipo 1.
Queste grammatiche sono anche dette \keyword{grammatiche dipendenti dal contesto}.
\end{definition}

Chiaramente le grammatiche di tipo 1 sono incluse in quelle di tipo 1 e si dimostra facilmente che l'inclusione è stretta.
Noi trascureremo queste grammatiche perchè quasi tutti i linguaggi artificiali, quali i linguaggi di programmazione,
sono generati da una grammatica più ristretta.
Le grammatiche di tipo 1 sono invece utilizzate nell'analisi dei linguaggi naturali.


\begin{definition}\label{def:tipo-2}\label{def:CFG}
Ogni grammatica \gramm di tipo 0 per cui tutte le sue produzioni hanno testa formata da esattamente una variabile e per
coda una forma sentenziale non vuota è di tipo 2.
Queste grammatiche sono anche dette \keyword{grammatiche libere dal contesto}.
\end{definition}

Quasi tutti i linguaggi artificiali sono generati da grammatiche di tipo 2: per questo motivo saranno oggetto di uno
studio estensivo in questo testo.
Spesso però siamo interessati ad ulteriori restrizioni.

\begin{definition}\label{def:tipo-3}
Ogni grammatica \gramm di tipo 0 per cui tutte le sue produzioni sono forma $A\to aB$ o $A\to a$, dove $A$ e $B$ sono
variabili e $a$ è un terminale, è di tipo 3.
Queste grammatiche sono anche dette \keyword{grammatiche regolari}.
\end{definition}

In realtà questa gerarchia ammette la possibilità di classi di grammatiche intermedie fra una classe e un'altra.
Vedremo nella \cref{part:parser} diverse classi di grammatiche che sono strettamente incluse in quelle di tipo 2 e
includono strettamente quelle di tipo 3.

Con un leggero abuso di linguaggio, talvolta diremo che un linguaggio è di tipo 0, 1, 2, 3 se è generato da una
grammatica di tipo 0, 1, 2, 3.

\section{Automi}\label{sec:automi}

Nella sezione precedente abbiamo introdotto il concetto di linguaggio generato da una grammatica che collega grammatiche
e linguaggi.
In questa sezione collegheremo classi di linguaggi con il modello di calcolo, o classe di automi, più semplice in grado di
risolvere il corrispondente problema di appartenza.
Non introduciamo una definizione formale di modello di calcolo che unifichi il concetto, ma introdurremo gli specifici
modelli per ogni classe di grammatiche che andremo a studiare.
Sintetizziamo nella \cref{tab:linguaggi-modelli-grammatiche} le relazioni che svilupperemo più avanti.


\begin{table*}[h!]\label{tab:linguaggi-modelli-grammatiche}
	\caption{Grammatiche, linguaggi e modelli di calcolo}
	\begin{tabular}{p{2.8cm} p{4.0cm} p{7.0cm}}
		\toprule
		Linguaggi di tipo   & Grammatiche   & Modello di calcolo \\
		\midrule
		0   & senza restrizioni       & Macchina di Turing        \\
		1     & dipendenti dal contesto     & Macchina di Turing con spazio lineare  \\
		2   & libere dal contesto     & Automi a pila      \\
		3   & regolari     & Automi a stati finiti      \\
		\bottomrule
	\end{tabular}
\end{table*}




\section{Grammatiche Context-Free}\label{sec:CFG}

\begin{example}
	Sia $G=(V,T,O,E)$, con $V=\{E,I\}$ e $T=\{a,b,0,1,(,),+,*\}$
	quindi ho le seguenti regole, è di tipo 3:
	\begin{enumerate}
		\item $E\to I$
		\item $E\to E+E$
		\item $E\to E*E$
		\item $E\to (E)$
		\item $I\to a$
		\item $I\to b$
		\item $I\to Ia$
		\item $I\to Ib$
		\item $I\to I0$
		\item $I\to I1$
	\end{enumerate}
	voglio ottenere $a*(a+b00)$
	sostituisco sempre a destra (right most derivation)
	$$E\to E*E\to E*(E)\to E*(E+E)\to E*(E+I)\to E+(E+I0)$$
	$$\to R+(I+b00)\to E*(a+b00)\to I*(a+b00)\to a*(a+b00)$$

	usiamo ora \textit{l'inferenza ricorsiva}:
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			passo & stringa ricorsiva & var & prod & passo stringa impiegata \\
			1     & a                 & I   & 5    & $\backslash$            \\
			\hline
			2     & b                 & I   & 6    & $\backslash$            \\
			\hline
			3     & b0                & I   & 9    & 2                       \\
			\hline
			4     & b00               & I   & 9    & 3                       \\
			\hline
			5     & a                 & E   & 1    & 1                       \\
			\hline
			6     & b00               & E   & 1    & 4                       \\
			\hline
			7     & a+b00             & E   & 2    & 5,6                     \\
			\hline
			8     & (a+b00)           & E   & 4    & 7                       \\
			\hline
			9     & a*(a+b00)         & E   & 3    & 5, 8                    \\
			\hline
		\end{tabular}
	\end{center}
\end{example}
definisco formalmente la derivazione $\to$:
\begin{definition}
	Prendo una grammatica $G=(V,T,P,S)$, grammatica CFG. Se $\alpha A \beta$ è una stringa tale che $\alpha,\beta\in (V\cup T)^*$, appartiene sia a variabili che terminali. Sia $A\in V$ e sia $a\to \gamma$ una produzione di $G$. Allora
	scriviamo:
	$$\alpha A \beta \to \alpha\gamma\beta$$
	con $\gamma\in (V\cup T)^*$.\\
	Le sostituzioni si fanno indipendentemente da $\alpha$ e $\beta$.
	Questa è quindi la definizione di derivazione.
\end{definition}
\begin{definition}
	Definisco il simbolo $\to _*$, ovvero il simbolo di \textit{derivazioni in 0 o più passi}. Può essere definito in modo ricorsivo. Per induzione sul numero di passi.
	\begin{itemize}
		\item la base dice che  $\forall \alpha\in (V\cup T)^*,\, \alpha\to * \,\alpha$
		\item il passo è: se $\alpha\to_{G_*} \,\beta $ e $ \beta \to_{G_*} \,\gamma$ allora $\alpha\to_* \,\gamma$
	\end{itemize}
	Si può anche dire che $\alpha\to_{G_*}\, \beta$ sse esiste una sequenza di stringhe $\gamma_1,...,\gamma_n$ con $n\geq 1$ tale che $\alpha=\gamma_1$, $\beta=\gamma_n$ e $\forall i,\, 1<i<n-1$ si ha che $\gamma_1\to \gamma_{i+1}$
	la derivazione in 0 o più passi è la chiusura transitiva della derivazione
\end{definition}
\begin{definition}
	avendo ora definito questi simboli possiamo definire una forma sentenziale. Infatti è una stringa $\alpha$ tale che:
	$$\forall \alpha\in (V\cup T)^* \mbox{ tale che }S\to_{G_*}\, \alpha$$
\end{definition}
\begin{definition}
	data $G=(V,T,P,S)$ si ha che $L(G)=\{w\in T^* |\, S\to_{G_*}\, w\}$ ovvero composto da stringhe terminali che sono derivabili o 0 o più passi.
\end{definition}
\begin{example}
	formare una grammatica CFG per il linguaggio:
	$$L=\{0^n 1^n| n\geq 1\}=\{01, 0011, 000111,...\}$$
	con $x^n$ intendo una concatenazione di $n$ volte $x$ (che nel nostro caso sono 0 e 1).\\
	posso scrivere:
	$$0^n 1^n =00^{n-1} 1^{n-1}1$$
	il nostro caso base sarà la stringa $01$, Poi si ha:
	$G=(V,T,P,S)$, $T=\{0,1\}$, $V=\{S\}$, il caso base $S\to 01$  e $S\to 0S1$
	il caso passo è quindi: se $w= 0^{n-1}1^{n-1}\in L$ allora $0w1\in L$.\\
	Ora voglio dimostare che $000111\in L$, ovvero $S\to*\, 000111$:\\
	$$S\to\, 0S1 \to 00S11\to 000S111$$
\end{example}
\begin{theorem}
	data la grammatica $G=\{V,T,P,S)$ CFG e $\alpha\in (V\cup T)^*$. Si ha che vale $S\to_*\, \alpha$ sse $S\to_{lm_*}\, \alpha$ sse $S\to_{rm_*}\, \alpha$. Con $\to_{lm_*}$ simbolo di \textit{left most derivation }e $\to_{rm_*}$ simbolo di \textit{right most derivation}
\end{theorem}
\begin{example}
	formare una grammatica CFG per il linguaggio:
	$$L=\{0^n 1^n| n\geq 0\}=\{\varepsilon, 01, 0011, 000111,...\}$$
	stavolta abbiamo anche la stringa vuota. Il caso base stavolta è $S\to\varepsilon| \, 0S1$
\end{example}
\begin{example}
	Fornisco una CFG per $L=\{a^n|n\geq 1\}=\{a, aa, aaa,...\}$.
	La base è $a$ \\il passo è che se $a^{n-1}\in L$ allora $a^{n-1}a\in L$ ( o che $aa^{n-1}\in L$).\\
	Si ha la grammatica $G=\{V,T,P,S)$, $V=\{S\}$, $T=\{a\}$ e si hanno $S\to a|\,Sa$ (o  $S\to a|\,aS$). Dimostro che $a^3\in L$.
	$$S\to Sa \to Saa\to aaa$$
	oppure
	$$S\to aS\to aaS\to aaa$$
\end{example}
\begin{example}
	trovo una CFG per $L=\{(ab)^n|n\geq 1\}=\{ab, abab, ababab,...\}$\\
	La base è $ab$ \\il passo è che se $(ab)^{n-1}\in L$ allora $(ab)^{n-1}ab\in L$.\\
	Si ha la grammatica $G=\{V,T,P,S)$, $V=\{S\}$, $T=\{a,b\}$ (anche se in realtà $T=\{ab\}$) e si hanno $S\to ab|\,Aab$. Poi dimostro come l'esempio sopra
\end{example}
\begin{example}
	trovo una CFG per $L=\{a^n c b^n|n\geq 1\}=acb,aacbb,aaacbbb,...\}$\\
	Il caso base è $acb$ il passo è che se $a^{n-1}cb^{n-1}\in L$ allora $a^{n-1}cb^{n-1}acb\in L$
	Si ha la grammatica $G=\{V,T,P,S)$, $V=\{S\}$, $T=\{a,b,c\}$ e si hanno $S\to aSb|acb$.\\
	dimostro che $aaaacbbbbb\in L$:
	$$S\to aSb\to aaSbb\to aaaaSbbb\to aaaacbbbb$$

	provo a usare anche una grammatica regolare, con le regole $S\to aS|c$, $c\to cB$ e $B\to bB|b$;
	$$S\to aS\to aaS\to aaC\to aacB\to aacb...$$
	non si può dimostrare in quanto non si può imporre una regola adatta
\end{example}
\begin{example}
	$L=\{a^n c b^{n-1}|n\geq 2\}$, con $a^n c b^{n-1}=a^{n-1}acb^{n-1}$. $S\to aSb|aacb$. Quindi:
	$$S\to aSb\to aaaccbb\in L$$
\end{example}
\begin{example}
	cerco CFG per $L=\{a^n c^k b^n|\,n,\,k>0\}$. $a$ e $b$ devono essere uguali, uso quindi una grammatica context free, mentre $c$ genera un linguaggio regolare.\\
	Si ha la grammatica $G=\{V,T,P,S)$, $V=\{S,C\}$, $T=\{a,b,c\}$ e si hanno $S\to aSb|aCb$ e $C\to cC|c$. dimostro che $aaaccbbb\in L, n=3,\, k=2$:
	$$S\to aSb \to aaSbb\to aaaCbbb\to aaacCbbb\to aaaccbbb$$
\end{example}
\begin{example}
	scrivere CFG per $L=\{a^nb^nc^kb^k|\, n,\,k\geq 0\}
	$
	$$=\{w\in\{a,b,c,d\}^*|\,a^nb^nc^kb^k|\, n,\,k\geq 0\}$$
	quindi L concatena due linguaggi $L1$ e $L2$, $X=\{a^nb^n\}$ e $Y=\{c^kd^k\}$:
	$$X\to aXb | \varepsilon$$
	$$Y\to cYd | \varepsilon$$
	$$S\to XY$$
	voglio derivare $abcd$:
	$$S\to XY \to XcYd\to aXbcYd\to aXbc\varepsilon d\to a\varepsilon bc\varepsilon d\to abcd$$
	voglio derivare $cd$
	$$S\to XY\to Y\to cYd\to cd$$
\end{example}
Quindi se ho $w\in L1, L2$, ovvero appartenente ad una concatenazione di linguaggi prima uso le regole di un linguaggio, poi dell'altro e infine ottengo il risultato finale.\\
\begin{example}
	scrivere CFG per $L=\{a^nb^kc^kd^n|\, n>0,\, k\geq 0\}
	$.
	$$S\to aSd|\, aXd$$
	$$X\to bXc| \varepsilon$$
	derivo $aabcdd$:
	$$S\to aSd\to aaXdd\to aabXcdd\to aabcdd$$
\end{example}
\begin{example}
	scrivere CFG per $L=\{a^ncb^nc^mad^m|\, n>0,\, m\geq 1\}
	$.
	$$S\to XY$$
	$$X\to aXb|c$$
	$$Y\to cUd| cad$$
	$$S\to XY\to cY\to ccad$$
\end{example}
\begin{example}
	scrivere CFG per $L=\{a^{n+m}xc^nyd^m|\, n,\, m\geq 0\}
	$. $a^{n+m}=a^na^m \mbox{ o } a^ma^n$. Si hanno 2 casi:
	\begin{enumerate}
		\item $L=\{a^na^m xc^nyd^m|\, n,\, m\geq 0\}
					$
		\item $L=\{a^ma^n xc^nyd^m|\, n,\, m\geq 0\}
					$
	\end{enumerate}
	ma solo  $L=\{a^ma^n xc^nyd^m|\, n,\, m\geq 0\}
	$ può generare una CFG (dove non si possono fare incroci, solo concatenazioni e inclusioni/innesti).
	$$S\to aSd| Y$$
	$$Y\to Xy$$
	$$X\to aXc|x$$
	si può fare in 2:
	$$S\to aSd| Xy$$
	$$X\to aXc|x$$
	derivo con $m=n=1$, $aaxcyd$:
	$$S\to aSd\to aXyd\to aaXcyd\to aaxcyd$$
\end{example}
\begin{example}
	scrivere CFG per $L=\{a^nb^m|\, n\geq m \geq 0\}
	$.$$L=\{\varepsilon, a, ab, aa, aab, aabb, aaa, aaab, aaabb, aaabbb,...\}$$
	Se $n\geq m$ allora $\exists k\geq 0 \to n=m+k$. Quindi:
	$$l=\{a^{m+k}b^m|m,k\geq0\}$$ si può scrivere in 2 modi:
	\begin{enumerate}
		\item $l=\{a^ma^kb^m|m,k\geq0\}$ quindi con innesto
		\item $l=\{a^ka^mb^m|m,k\geq0\}$quindi con concatenazione
	\end{enumerate}
	entrambi possibili per una CFG:
	\begin{enumerate}
		\item
					$$S\to XY$$
					$$X\to aX|\varepsilon \mbox{ si può anche scrivere } X\to Xa|\varepsilon$$
					$$Y\to aYb|\varepsilon$$
					oppure
					$$S\to aS|X$$
					$$X\to aXb| \varepsilon$$
		\item
					$$S\to aSb|\varepsilon$$
					$$X\to aX|\varepsilon$$
	\end{enumerate}
\end{example}
\begin{example}
	scrivere CFG per $L=\{a^nb^{m+n}c^h|\, m>h\geq0,\, n\geq0\}
	$.\\
	Se $n>h$ allora $\exists k \to n= h+k$, quindi:
	$$L=\{a^nb^{m+h+k}c^h|\, m>h\geq0,\, n\geq0\}$$. ovvero:
	$$L=\{a^nb^nb^kb^hc^h|\, m\geq 0, k>0, h\geq 0\}$$
	si ha:
	$$S\to XYZ$$
	$$X\to aXb|\varepsilon$$
	$$Y\to Yb|b$$
	$$Z\to bZc|\varepsilon$$
	si può anche fare:
	$$S\to XY$$
	$$X\to aXb|\varepsilon$$
	$$Y\to bYc|Z$$
	$$Z\to bZ|b$$
\end{example}
\begin{example}
	scrivere CFG per $L=\{a^nb^mc^k|\, k>n+m,\, n,m\geq 0\}
	$.\\
	per $n=m=0,\, k=1$ avrò la stringa $c$.
	se $k>n+m$ allora $\exists l>0\to k=n+m+l$ quindi:
	$$L=\{a^nb^mc^{n+m+l}|\, l>0,\, n,m\geq 0\}
	$$
	$$=L=\{a^nb^mc^nc^mc^l|\, l>0,\, n,m\geq 0\}$$
	sistemando:
	$$=L=\{a^nb^mc^lc^mcnl|\, l>0,\, n,m\geq 0\}$$
	quindi:
	$$S\to aSc|X$$
	$$X\to bXc|Y$$
	$$Y\to cY|c$$
\end{example}
\newpage
\begin{example}
	scrivere CFG per $L=\{a^nxc^{n+m}y^hz^kd^{m+h}|\, n,m,k,h\geq 0\}
	$.\\
	ovvero:
	$$L=\{a^nxc^nc^my^hz^kd^hd^m|\, n,m,k,h\geq 0\}$$
	quindi avrò:
	$$S\to XY$$
	$$X\to aXc|x$$
	$$Y\to cYd|W$$
	$$W\to yWd|X$$
	$$Z\to zZ|\varepsilon$$
\end{example}
\begin{example}
	vediamo un esempio di grammatica dipendente dal contesto:
	$$L=\{a^nb^nc^n|\, n\geq 1\}$$
	$G=\{V,T,P,S\}=\{(S,B,C,X)\}=\{(a,b,c),P,S\}$
	ecco le regole di produzione (qui posso scambiare variabili a differenza delle context free):
	\begin{enumerate}
		\item $S\to aSBC$
		\item $S\to aBC$
		\item $CB\to XB$
		\item $XB\to XC$
		\item $XC\to BC$
		\item $aB\to ab$
		\item $bB\to bb$
		\item $bC\to bc$
		\item $cC\to cc$
	\end{enumerate}
	vediamo un esempio di derivazione:
	per $n=1$ ho $abc$ ovvero:
	$$S\to aBC\to abC\to abc$$
	con $n=2$ ho $aabbcc$:
	$S\to aSBC\to aaBCBC\to aaBXBC\to aaBXCC\to aaBBCC\to aabBCC\to aabbCC\to aabbcC\to aabbcc$\\
	%vedere dimostrazione pag 14 soligo
\end{example}
\newpage
\begin{example}
	vediamo un esempio di grammatica dipendente dal contesto:
	$$L=\{a^nb^mc^nd^m|\, n,m\geq 1\}$$
	Si ha:
	$$G=(\{S,X,C,D,Z\},\{a,b,c,d\},P,S)$$
	con le seguenti regole di produzione:
	\begin{itemize}
		\item $S\to aSc|\, aXc$
		\item $X\to bXD|\, bD$
		\item $DC\to CD$
		\item $DC\to DZ$
		\item $DZ\to CZ$
		\item $XZ\to CD$
		\item $bC\to bc$
		\item $cC\to cc$
		\item $cD\to cd$
		\item $dD\to dd$
	\end{itemize}
	provo a derivare $aabbbccddd$ quindi con $n=2,\,m=3$:\\
	$$S\to aSC\to aaXCC\to aabXDCC\to aabbXDDCC\to $$
	$$aabbbDDDCC\to aabbbCCDDD\to aabbbccddd$$
\end{example}
\begin{example}
	Sia $L=\{w\in\{a,b\}^*|\, \mbox{ w contiene lo stesso numero di a e b}\}$:
	$$S\to aSbS|\,bSaS|\, \varepsilon$$
	dimostro per induzione che è corretto:
	\begin{itemize}
		\item \textbf{caso base:} $|w|=0\to w=\varepsilon$
		\item \textbf{caso passo:} si supponga che $G$ produca tutte le stringhe (di lunghezza $<$ di $n$) di $\{a,b\}^*$ con lo stesso numero di \textit{a} e \textit{b} e dimostro che produce anche quelle di lunghezza $n$, sia:
					$$w\in \{a,b\}^* \mid\, |w|=n \mbox{ con\textit{ a} e \textit{b} in egual numero, }m(a)=m(b) \mbox{ con m() che indica il numero di caratteri}$$
					quindi si ha che:
					$$w=aw_1bw_2\mbox{ o } w=bw_1aw_2$$
					sia.
					$$k_1=m(a)\in w_1=m(b)\in w_1$$
					$$k_2=m(a)\in w_2=m(b)\in w_2$$
					allora:
					$$k_1+k_2+1=m(a)\in w= m(b)\in W$$
					sapendo che $|w_1|<n$ e $|w_2|<n$ allora $w_1$ e $w_2$ sono egnerati da G per ipotesi induttiva
	\end{itemize}
\end{example}

\section{Alberi Sintatici}
\begin{definition}
	Data una grammatica CFG, $G=\{V,T,P,S\}$ un \textbf{albero sintattico} per $G$ soddisfa le seguenti condizioni:
	\begin{itemize}
		\item ogni nodo interno è etichettato con una variabile in $V$
		\item ogni foglia è anch'essa etichettata con una variabile o col simbolo di terminale T o con la stringa vuota $\varepsilon$ (in questo caso la foglia è l'unico figlio del padre)
		\item se un nodo interno è etichettato con A i suoi figli saranno etichettati con X1, ..., Xk e $A\to  X1, ..., Xk$ sarà una produzione di $G$ in $P$. Se un $X_i$ è $\varepsilon$ sarà l'unica figlio e $A\to \varepsilon$ sarà comunque una produzione di $G$
	\end{itemize}
	La concatenazione in ordine delle foglie viene detto \textbf{prodotto dell'albero}
\end{definition}
\newpage
\begin{example}
	Usiamo l'esempio delle stringhe palindrome:
	$$P\to 0P0|\,1P1|\varepsilon$$
	sia il seguente albero sintatico:
	\begin{center}
\includegraphics{example_1.1.1.png
}
%		\psframebox[linestyle=none,framesep=10pt]{%
%			\pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]P}}{\pstree{\Tp[edge=none]}{%
%					\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]0}
%					\pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]P}}{\pstree{\Tp[edge=none]}{%
%							\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]1}
%							\pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]P}}{\pstree{\Tp[edge=none]}{%
%									\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]$\varepsilon$}}}
%							\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]1}}}
%					\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]0}}}}
	\end{center}
\end{example}
\begin{example}
	Si ha:
	$$E\to I|\, E+E|\, E*E|\, (E)$$
	$$I\to a|\,b|\,Ia|\,Ib|\,I0|\,I1$$
	un albero sintattico per $a*(a+b00)$ può essere:
	\begin{center}
\includegraphics{example_1.1.2.png}
%		\psframebox[linestyle=none,framesep=10pt]{%
%			\pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}}{\pstree{\Tp[edge=none]}{%
%					\pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}}{\pstree{\Tp[edge=none]}{%
%							\pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]I}}{\pstree{\Tp[edge=none]}{%
%									\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]a}}}}}
%					\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]*}
%					\pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}}{\pstree{\Tp[edge=none]}{%
%							\LFTw{t}{\fontspec{Noto Sans}[Script=Latin](}
%								\pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}}{\pstree{\Tp[edge=none]}{%
%										\pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}}{\pstree{\Tp[edge=none]}{%
%												\pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]I}}{\pstree{\Tp[edge=none]}{%
%														\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]a}}}}}
%										\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]+}
%										\pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}}{\pstree{\Tp[edge=none]}{%
%												\pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]I}}{\pstree{\Tp[edge=none]}{%
%														\pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]I}}{\pstree{\Tp[edge=none]}{%
%																\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]b}}}
%														\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]0}}}
%												\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]0}}}}}
%								\LFTw{t}{\fontspec{Noto Sans}[Script=Latin])}}}}}}
	\end{center}
\end{example}
\newpage
Data una CFG si ha che i seguenti cinque enunciati si equivalgono:
\begin{enumerate}
	\item la procedura di inferenza ricorsiva stailisce che una stringa $w$ di simboli terminali appartiene al linguaggio $L(A)$ con $A$ variabile
	\item $A\to ^*w$
	\item $A\to^*_{lm}w$
	\item $A\to^*_{rm}w$
	\item esiste un albero sintattico con radice $A$ e prodotto $w$
\end{enumerate}
queste 5 proposizioni si implicano l'uni l'altra:
\begin{center}
	\begin{tikzpicture}
		\node (top) at (0,0) {5};
		\node (a) at(-1,-0.5) {3};
		\node (b) at(0,-1) {4};
		\node (c) at(-2.0,-1.85) {2};
		\node (d) at(1.5,-2) {1};
		\draw [->] (top) -- (a);
		\draw [->] (top) -- (b);
		\draw [->] (a) -- (c);
		\draw [->] (b) -- (c);
		\draw [->] (c) -- (d);
		\draw [->] (d) -- (top);
	\end{tikzpicture}
\end{center}
vediamo qualche dimostrazione di implicazione tra queste proposizioni:
\begin{proof}[da 1 a 5]
	si procede per induzione:
	\begin{itemize}
		\item \textbf{caso base:} ho un livello solo (una sola riga), $\exists A\to w$:
					$$\overset{A}{\overset{\triangle}w}$$
		\item \textbf{caso passo:} suppongo vero per un numero di righe $\leq n$, lo dimsotro per $n+1$ righe:
					$$A\to X_1,X_2,...,X_k$$
					$$w=w_1,w_2,...,w_k$$
					ovvero, in meno di $n+1$ livelli:
					\begin{center}
\includegraphics{caso_passo.png}
					% \psframebox[linestyle=none,framesep=10pt]{%
%				      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]A}}{\pstree{\Tp[edge=none]}{%
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]$\overset{X_1}{\overset{\triangle}w_1}$}
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]$\overset{X_2}{\overset{\triangle}w_2}$}
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]$\vdots$}
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]$\overset{X_k}{\overset{\triangle}w_k}$}}}}
					\end{center}
	\end{itemize}
\end{proof}
\begin{proof}[da 5 a 3]
	procedo per induzione:
	\begin{itemize}
		\item \textbf{caso base (n=1): }$\exists A\to w\mbox{ quindi } A\to_{lm}w$, come prima si ha un solo livello:
					$$\overset{A}{\overset{\triangle}w}$$
		\item \textbf{caso passo: }suppongo che la proprierà valga per ogni albero di profondità minore uguale a $n$, dimostro che valga per gli alberi profondi $n+1$:
					$$A\to X_1,X_2,...,X_k$$
					$$w=w_1,w_2,...,w_k$$
					ovvero, in meno di $n+1$ livelli:
					\begin{center}
\includegraphics{caso_passo.png}
%			      \psframebox[linestyle=none,framesep=10pt]{%
%				      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]A}}{\pstree{\Tp[edge=none]}{%
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]$\overset{X_1}{\overset{\triangle}w_1}$}
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]$\overset{X_2}{\overset{\triangle}w_2}$}
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]$\vdots$}
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]$\overset{X_k}{\overset{\triangle}w_k}$}}}}
					\end{center}
					$$A\to_{lm} X_1,X_2,...,X_k$$
					$$x_1\to^*_{lm}w_1 \mbox{ per ipotesi induttiva si ha un albero al più di n livelli}$$
					quindi:
					$$A\to_{lm}X_1,...,X_k\to^*_{lm}w_1,X_2,...,X_k\to^*_{lm}...\to^*_{lm}w_1,...,w_k=w$$
	\end{itemize}
	\begin{example}
		$$E\to I\to Ib\to ab$$
		$$\alpha E\beta\to\alpha I\beta\to \alpha Ib\beta\to \alpha ab\beta,\,\,\,\alpha,\beta\in(V\cup T)^*$$
	\end{example}
\end{proof}
\begin{example}
	Mostro l'esistenza di una derivazione sinistra dell'albero sintattico di $a*(a+b00)$:
	$$E\to^*_{lm}E*E\to^*_{lm}I*E\to^*_{lm}a*E\to^*_{lm}a*(E)\to^*_{lm}a*(E+E)\to^*_{lm}$$
	$$a*(I+E)\to^*_{lm}a*(a+E)\to^*_{lm}a*(a+I)\to^*_{lm}a+(a+I0)\to^*_{lm}a*(a+I00)\to^*_{lm}a*(a+b00)$$
\end{example}
\section{Grammatiche ambigue}
\begin{definition}
	Una grammatica è definita ambigua se esiste una stringa $w$ di terminali che ha più di un albero sintattico
\end{definition}
\begin{example}
	vediamo un esempio:
	\begin{enumerate}
		\item $E\to E+E\to E+E*E$
					ovvero:
					\begin{center}
\includegraphics{ambigua1.png}
%			      \psframebox[linestyle=none,framesep=10pt]{%
%				      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}}{\pstree{\Tp[edge=none]}{%
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]+}
%						      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}}{\pstree{\Tp[edge=none]}{%
%								      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}
%								      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]*}
%								      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}}}}}}
					\end{center}
		\item $E\to E*E\to E+E*E$
					ovvero:
					\begin{center}
%			      \psframebox[linestyle=none,framesep=10pt]{%
%				      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}}{\pstree{\Tp[edge=none]}{%
%						      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}}{\pstree{\Tp[edge=none]}{%
%								      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}
%								      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]+}
%								      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}}}
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]*}
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]E}}}}
					\end{center}
	\end{enumerate}
	si arriva a due stringhe uguali ma con alberi diversi. Introduciamo delle categorie sintatiche, dei vincoli alla produzione delle regole:
	\begin{enumerate}
		\item $E\to T|\, E+T$
		\item $T\to F|\, T+F$
		\item $F\to I|\, (E)$
		\item $I\to a|\,b|\,Ia|,Ib|\,I0|\,I1$
	\end{enumerate}
\end{example}
Possono esserci più derivazioni di una stringa ma l'importante è che non ci siano alberi sintattici diversi. Capire se una CFG è ambigua è un problema indecidibile
\begin{example}
	vediamo un esempio:
	$$S\to \varepsilon|\,SS|\, iS|\, iSeS$$
	con S=statement, i=if e e=else. Considero due derivazioni:
	\begin{enumerate}
		\item $S\to iSeS\to iiSeS\to iie$:
					\begin{center}
\includegraphics{ambigua2.png}

%			      \psframebox[linestyle=none,framesep=10pt]{%
%				      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]S}}{\pstree{\Tp[edge=none]}{%
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]i}
%						      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]S}}{\pstree{\Tp[edge=none]}{%
%								      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]i}
%								      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]S}}{\pstree{\Tp[edge=none]}{%
%										      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]$\varepsilon$}}}}}
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]e}
%						      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]S}}{\pstree{\Tp[edge=none]}{%
%								      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]$\varepsilon$}}}}}}\end{center}
%		\item $S\to iS\to iiSeS\to iieS\to iie$:
%		      \begin{center}
%
%			      \psframebox[linestyle=none,framesep=10pt]{%
%				      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]S}}{\pstree{\Tp[edge=none]}{%
%						      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]i}
%						      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]S}}{\pstree{\Tp[edge=none]}{%
%								      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]i}
%								      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]S}}{\pstree{\Tp[edge=none]}{%
%										      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]$\varepsilon$}}}
%								      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]e}
%								      \pstree{\LFTw{t}{\fontspec{Noto Sans}[Script=Latin]S}}{\pstree{\Tp[edge=none]}{%
%										      \LFTw{t}{\fontspec{Noto Sans}[Script=Latin]$\varepsilon$}}}}}}}}
					\end{center}
	\end{enumerate}
	Si ha quindi una grammatica ambigua
\end{example}
\begin{theorem}
	Per ogni CFG, con $G=(V, T, P, S)$, per ogni stringa $w$ di terminali si ha che $w$ ha due alberi sintattici distinti sse ha due derivazioni sinistre da S distinte.\\
	Se la grammatica non è ambigua allora esiste un'unica derivazione sinistra da $S$
\end{theorem}
\subsubsection{Linguaggi inerentemente ambigui}
\begin{definition}
	Un linguaggio $L$ è inerentemente ambiguo se tutte le grammatiche CFG per tale linguaggio sono a loro volta ambigue
\end{definition}
\begin{example}
	Sia $L=\{a^nb^nc^md^m|\, n,m\geq 1\}\cup \{a^nbmnc^md^n|\, n,m\geq 1\}$\\
	si ha quindi un CFL formato dall'unione di due CFL. $L$ è inerentemente ambiguo e generato dalla seguente grammatica:
	\begin{itemize}
		\item $S\to AB|\,C$
		\item $A\to aAb|\,ab$
		\item $B\to cBd|\, cd$
		\item $C\to aCd|\, aDd$
		\item $D\to bDc|\, bc$
	\end{itemize}
	si possono avere due derivazioni:
	\begin{enumerate}
		\item $S\to_{lm}AB\to_{lm} aAbB\to_{lm} aabbB\to_{lm}aabbcBd\to_{lm}aabbccdd$
		\item $S\to_{lm} C\to_{lm} aCd\to_{lm}aaBdd\to_{lm}aabBcdd\to_{lm}aabbccdd$
	\end{enumerate}
	a generare problemi sono le stringhe con n=m perché possono essere prodotte in due modi diversi da entrambi i sottolinguaggi. Dato che l'intersezione tra i due sottolinguaggi non è buota si ha che $L$ è ambiguo
\end{example}
\section{Grammatiche Regolari}
Sono le grammatiche che generano i linguaggi regolari (quelli del terzo tipo) che sono casi particolari dei CFL.\\
Si ha la solita grammatica $G = (V, T, P, S)$ con però vincoli su $P$:
\begin{itemize}
	\item $\varepsilon$ si può ottenere solo con $S\to \varepsilon$
	\item le produzioni sono tutte lineari a destra ($A\to aA$ o $A\to a$) o a sinistra ($A\to Ba$ o $A\to a$)
\end{itemize}
\begin{example}
	$I\to a|\,b|\,Ia|\,Ib|\,I0|\,I1$ è una grammatica con le produzioni lineari a sinistra.\\
	Potremmo pensarlo a destra $I\to a|\,b|\,aI|\,bI|\,0I|\,1I$.\\
	Vediamo esempi di produzione con queste grammatiche:
	\begin{itemize}
		\item con $I\to a|\,b|\,Ia|\,Ib|\,I0|\,I1$ possiamo derivare $ab01b0$:
					$$I\to I0\to Ib0\to I1b0\to I01b0\to Ib01b0\to ab01b0$$
		\item con $I\to a|\,b|\,aI|\,bI|\,0I|\,1I$ invece non riusciamo a generare nulla:
					$$I\to 0I\to 0a$$
	\end{itemize}
	definisco quindi un'altra grammatica (con una nuova categoria sintattica):
	$$I\to aJ|\, bJ$$
	$$J\to a|\,b|\,aJ|\,bJ|\,0J|\,1J$$
	che però non mi permette di terminare le stringhe con 0 e 1, la modifico ancora otterdendo:
	$$I\to aJ|\, bJ$$
	$$J\to a|\,b|\,aJ|\,bJ|\,0J|\,1J|\,0|\,1$$
	e questo è il modo corretto per passare da lineare sinistra a lineare destra
\end{example}
\begin{example}
	Sia $G=(\{S\},\{0,1\},P,S)$ con $S\to \varepsilon|\,0|\,1|\,0S|\,1S$. Si ha quindi:
	$$L(G)=\{0,1\}^*$$
	si hanno comunque due proposizioni ridondanti, riducendo trovo:
	$$S\to \varepsilon|\, 0S|\,1S$$
	con solo produzioni lineari a destra. Con produzioni lineari a sinistra ottengo:
	$$S\to \varepsilon|\, S0|\,S1$$
\end{example}
\begin{example}
	Trovo una grammatica lineare destra e una sinistra per $L=\{a^nb^m|\,n,m\geq 0\}$:
	\begin{itemize}
		\item \textbf{lineare a destra:} si ha $G=(\{S,B\},\{a,b\},P,S)$ e quindi:
					$$S\to \varepsilon|\,aS|\,bB$$
					$$B\to bB|\,b$$
					ma non si possono generare stringhe di sole $b$, infatti:
					$$S\to aS\to abB\to abbB\to abbb$$
					ma aggiungere $\varepsilon$ a B \textbf{non è lecito}. posso però produrre la stessa stringa da due derivazioni diverse:
					$$S\to \varepsilon|\,aS|\,bB|\,b$$
					$$B\to bB|\,b$$
					che risulta quindi la nostra lineare a destra
		\item \textbf{lineare a sinistra:} si ha $G=(\{S,A\},\{a,b\},P,S)$ e quindi:
					$$S\to \varepsilon|\,Sb|\,Ab|\,a$$
					$$A\to Aa|\,a$$
	\end{itemize}
\end{example}
\begin{example}
	Trovo una grammatica lineare destra e una sinistra per $L=\{ab^ncd^me|\,n\geq 0\,,m> 0\}$:
	\begin{itemize}
		\item \textbf{lineare a destra:} si ha  si ha $G=(\{S,A,B,E\},\{a,b,c,d,e\},P,S)$ e quindi:
					$$S\to aA$$
					$$A\to bA|\,cB$$
					$$B\to dB|\, dE$$
					$$E\to e$$
		\item \textbf{lineare a sinistra:} si ha  si ha $G=(\{S,X,Y,Z\},\{a,b,c,d,e\},P,S)$ e quindi:
					$$S\to Xe$$
					$$A\to Xd|\,Yd$$
					$$B\to Zc$$
					$$E\to a|\,Zb$$
	\end{itemize}
	quindi se per esempio ho la stringa "ciao" si ha:
	\begin{itemize}
		\item \textbf{lineare a destra:}
					$$S\to Ao$$
					$$A\to Ba$$
					$$B\to Ei$$
					$$E\to c$$
		\item \textbf{lineare a sinistra:}
					$$S\to cA$$
					$$A\to iB$$
					$$B\to aE$$
					$$E\to o$$
	\end{itemize}
\end{example}
\begin{example}
	A partire da $G=(\{S,T\},\{0,1\},P,S)$ con:
	$$S\to\varepsilon|\,0S|\,1T$$
	$$T\to 0T|\,1S$$

	trovo come è fatto $L(G)$:
	$$L(G)=\{w\in\{0,1\}^*|\, w \mbox{ ha un numero di 1 pari}\}$$
\end{example}
\begin{example}
	fornire una grammatica regolare a destra e sinistra per:
	$$L=\{w\in\{0,1\}^*|\, w \mbox{ ha almeno uno 0 o almeno un 1}\}$$
	Si ah che tutte le stringhe tranne quella vuota ciontengono uno 0 o un 1
	quindi  $G=(\{S\},\{0,1\},P,S)$:
	\begin{itemize}
		\item \textbf{lineare a destra:}
					$$S\to 0|\,1|\,0S|\,1S$$
		\item \textbf{lineare a sinistra:}
					$$S\to 0|\,1|\,S0|\,S1$$
	\end{itemize}
\end{example}



Vediamo ora un esempio di \textit{Context Free Language (CFL)}, costruito a partire da una \textit{Context Free Grammar (CFG)}:
\begin{example}
	Sia $\Sigma=\{0, 1\}$ e $L_{pal}="stringhe\,\, palindrome\,\, binarie"$.
	Quindi, per esempio, $0110\in L,\,\, 11011\in L$ ma $10010\not\in L$. Si ha che $\varepsilon$, la stringa vuota, appartiene a $L$. Diamo una definizione ricorsiva:
	\begin{itemize}
		\item \textbf{base:} $\varepsilon,\, 0\,\ 1\in L_{pal}$
		\item \textbf{passo:} se $w$ è palindroma allora $0w0$ è palindromo e $1w1$ è palindromo
	\end{itemize}
	una variabile generica $S$ può sottostare alle \textit{regole di produzione} di una certa grammatica. In questo caso si ha uno dei seguenti:
	$$S\to\varepsilon,\, S\to 0,\, S\to 1,\, S\to 0S0,\, S\to 1S1$$
\end{example}


riprendiamo l'esempio sopra:
\begin{example}
	$$G_{pal}=(V=\{S\},\, T=\{0, 1\},\, P,\, S)$$
	con:
	$$P=\{S\to\varepsilon,\, S\to 0,\, S\to 1,\, S\to 0S0,\, S\to 1S1\}$$
	Si può ora costruire un algoritmo per creare una stringa palindroma a partire dalla grammatica $G$:
	$$\underbrace{S}_{\mbox{start}}\underbrace{\to}_{\mbox{applico una regola}} 1S1 \to 01S10\to \underbrace{01010}_{\mbox{sostituisco variabile}}$$

	con $S,\, 1S1\,\, e\,\, 01S10$ che sono \textit{forme sentenziali}. Posso così ottenere tutte le possibili stringhe. Esiste anche una forma abbreviata:
	$$S\to \varepsilon|o|1|0S0|1S1$$
	Non si fanno sostituzioni in parallelo, prima una $S$ e poi un'altra
\end{example}

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../libro-linguaggi"
%%% TeX-engine: luatex
%%% End:
